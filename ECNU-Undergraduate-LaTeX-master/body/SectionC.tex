\section{评估NVIDIA新架构GPU的机器学习应用性能}
\subsection{实验动机、过程与结果}
\subsection{实验工具与环境}
\subsection{实验详细过程}
\subsubsection{基于测试样例的Benchmark}
\par 为了为接下来的实验设定基准，这一步先使用用途单一的测试样例测试绝对性能以及相应的提升，因不同架构的硬件各项参数(包括流处理器数量、显存容量等)不尽相同，所以直接对比不同架构硬件的性能是没有意义的，这里选择对比不同架构硬件在不同SDK下性能提升的比例。此处选用了CUDA 10.0，CUDA 9.2，CUDA 9.0三种SDK，同时选用9.2与9.0的原因是因为9.2版本是为了图灵架构的GPU Tesla V100发布的\parencite{CUDA92}，也在本文的研究范围内。
\par 因为本文主要讨论新架构GPU在机器学习应用中带来的性能提升，故选用的评测样例大部分都与机器学习应用相关；主要从以下角度进行评估：通用矩阵乘法(GEMM, General Matrix Multiply)、矩阵乘法运算性能、卷积运算性能、神经网络推理性能以及结合框架的综合性能。在评估这些性能时也会包含单/双精度浮点计算性能。
\paragraph{通用矩阵乘法(GEMM, General Matrix Multiply)}
\par 待评测项目中最为重要的是通用矩阵乘法(GEMM, General Matrix Multiply)，新架构对该运算进行了硬件、指令级别的优化，是与老架构最鲜明的区别所在。其混合体现在：运算中同时有加法和乘法，且精度同时涉及半精度浮点、单精度浮点和8位整数。与矩阵乘法相比，通用矩阵乘法被定义为：
$$ C \leftarrow \alpha AB + \beta C $$
\par 若将$ \beta $置为0，则该运算变为矩阵乘法运算。通用矩阵乘法这一运算在神经网络训练、推理中十分常见，根据官方文档，目前Tensor Core仅能用在CNN/RNN等特定结构的神经网络上，且只能用于前馈和反馈两部分。这个范围看起来很宅，然而在深度学习中占到了非常高的比重。式中操作数分别代表输入、权重和偏置，下文将简写为矩阵乘加。NVIDIA在新的伏特架构与图灵架构中加入的张量核心(Tensor Core)正是专门加速这种运算的硬件；对应新硬件，在PTX中间代码层面新增了$ wmma $指令，在SASS机器代码层面则增加了对应的$ hmma $指令。该指令的作用为以指定的精度计算两个输入矩阵的乘积并将计算结果累加到指定的精度的矩阵中；指令进行的具体操作、操作数的数据精度、形状、存储方式(行主元素/列主元素)等通过指令中特定的字段指定。
\par 在底层的实现中，张量核心以$ 4 \times 4 $的矩阵作为最小的计算单元，被称为$ tile $，任何输入都会被划分为$ tile $进行分块运算。在伏特架构以前(Volta)的帕斯卡架构(Pascal)，一次$ 4 \times 4 $矩阵乘加需要首先调用16次整数点积运算(若硬件支持$ idp/idp4a $指令)，再将结果累加到乘加矩阵中。而使用Tensor Core则仅通过$ hmma $指令直接完成。根据官方文档给出的描述，这种机制能使伏特架构相比帕斯卡架构再FP16, INT8, INT4京都中分别提供8倍、16倍、32倍的吞吐量提升。实际测试中，Tesla V100再FP16精度下的$ m=2048, k=2048, n = 2048 $规模的矩阵乘加中比Tesla P100块9.3倍\parencite{VOLTAWHITEPAPER}，这也是上文提到的官方宣称的9倍。本节将在各种规模、精度、形状的情况下考察Tensor Core实际能够带来的性能提升并探究相应原因。
\subparagraph{实验结果}
\par 根据开发者社区的反映，新架构硬件性能的差别主要体现在问题规模、问题类型等方面(张量维度、形状，训练/推理任务等)，而NVIDIA官方仅给出一种规模的结果，所以本节使用了自行编写的一系列测试用例，辅以深度学习测试套件DeepBench，在开启和关闭新架构中张量核心的情况下进行测试。实验性能使用TFlops/s统计，方法为简单的运算数除以运算时间，运算时间的统计采用CUDA内置的$ cudaEvent $记录。
\subparagraph{结果分析}
\paragraph{矩阵乘法运算}
\subparagraph{实验结果}
\subparagraph{结果分析}
\paragraph{卷积运算}
\subparagraph{实验结果}
\subparagraph{结果分析}
\paragraph{神经网络推理}
\subparagraph{实验结果}
\subparagraph{结果分析}
\subsubsection{基于CUDA源码的应用}
\paragraph{卷积神经网络}
\subparagraph{实验结果}
\subparagraph{结果分析}
\paragraph{并行支持向量机}
\subparagraph{实验结果}
\subparagraph{结果分析}
\subsubsection{基于TensorFlow框架的应用}
\subparagraph{实验结果}
\subparagraph{结果分析}