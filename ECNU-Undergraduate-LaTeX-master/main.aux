\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\abx@aux@refcontext{none/global//global/global}
\providecommand*\tocstyle@set@width[4]{}
\HyPL@Entry{0<</S/D>>}
\providecommand\tcolorbox@label[2]{}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\providecommand {\FN@pp@footnotehinttrue }{}
\providecommand {\FN@pp@footnote@aux }[2]{}
\FN@pp@footnotehinttrue 
\HyPL@Entry{1<</S/D>>}
\FN@pp@footnotehinttrue 
\FN@pp@footnotehinttrue 
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\thispagestyle {empty}}
\tocstyle@set@width {unum}{toc}{}{35.0pt}
\tocstyle@set@width {num}{toc}{1}{35.0pt}
\tocstyle@set@width {skip}{toc}{1}{0.0pt}
\tocstyle@set@width {num}{toc}{2}{17.5pt}
\tocstyle@set@width {skip}{toc}{2}{35.0pt}
\tocstyle@set@width {num}{toc}{3}{25.0pt}
\tocstyle@set@width {skip}{toc}{3}{35.56749pt}
\FN@pp@footnotehinttrue 
\HyPL@Entry{2<</S/R>>}
\FN@pp@footnotehinttrue 
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{摘要}{I}{figure.caption.1}}
\FN@pp@footnotehinttrue 
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{Abstract}{II}{figure.caption.1}}
\FN@pp@footnotehinttrue 
\abx@aux@cite{TESLAV100}
\abx@aux@segm{0}{0}{TESLAV100}
\abx@aux@cite{TENSORCORE}
\abx@aux@segm{0}{0}{TENSORCORE}
\abx@aux@cite{NVLINK2}
\abx@aux@segm{0}{0}{NVLINK2}
\abx@aux@cite{CUTLASS}
\abx@aux@segm{0}{0}{CUTLASS}
\abx@aux@cite{VOLTAWHITEPAPER}
\abx@aux@segm{0}{0}{VOLTAWHITEPAPER}
\abx@aux@cite{EXASCLEDL}
\abx@aux@segm{0}{0}{EXASCLEDL}
\abx@aux@cite{MODELING}
\abx@aux@segm{0}{0}{MODELING}
\abx@aux@cite{JETSONNANO}
\abx@aux@segm{0}{0}{JETSONNANO}
\abx@aux@cite{CUDAX}
\abx@aux@segm{0}{0}{CUDAX}
\HyPL@Entry{4<</S/D>>}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {第一章}引言}{1}{section.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}研究背景}{1}{subsection.1.1}}
\abx@aux@cite{GPUFORML}
\abx@aux@segm{0}{0}{GPUFORML}
\abx@aux@cite{KNNG}
\abx@aux@segm{0}{0}{KNNG}
\abx@aux@cite{SMOSVM}
\abx@aux@segm{0}{0}{SMOSVM}
\abx@aux@cite{BAYESINF}
\abx@aux@segm{0}{0}{BAYESINF}
\abx@aux@cite{JAPANESSAY}
\abx@aux@segm{0}{0}{JAPANESSAY}
\abx@aux@cite{LENET}
\abx@aux@segm{0}{0}{LENET}
\abx@aux@cite{NNML}
\abx@aux@segm{0}{0}{NNML}
\abx@aux@cite{GPGPUSIM}
\abx@aux@segm{0}{0}{GPGPUSIM}
\abx@aux@cite{GPGPUSIM2}
\abx@aux@segm{0}{0}{GPGPUSIM2}
\abx@aux@cite{NSIGHT}
\abx@aux@segm{0}{0}{NSIGHT}
\abx@aux@segm{0}{0}{VOLTAWHITEPAPER}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}目前展开的工作}{2}{subsection.1.2}}
\abx@aux@cite{DEEPBENCH}
\abx@aux@segm{0}{0}{DEEPBENCH}
\abx@aux@segm{0}{0}{LENET}
\abx@aux@cite{RESNET}
\abx@aux@segm{0}{0}{RESNET}
\abx@aux@cite{MOBILE}
\abx@aux@segm{0}{0}{MOBILE}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}我们的工作}{3}{subsection.1.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}本文的组织结构}{3}{subsection.1.4}}
\abx@aux@cite{EXPLORING}
\abx@aux@segm{0}{0}{EXPLORING}
\abx@aux@cite{HIER}
\abx@aux@segm{0}{0}{HIER}
\abx@aux@cite{CUDAPROG}
\abx@aux@segm{0}{0}{CUDAPROG}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {第二章}背景及相关工作}{4}{section.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}NVIDIA GPU硬件}{4}{subsection.2.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}GPU芯片总体结构}{4}{subsubsection.2.1.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subparagraph}{\numberline {I}流多处理器单元(SM)}{4}{subparagraph.2.1.1.0.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subparagraph}{\numberline {II}存储模型与管理}{4}{subparagraph.2.1.1.0.2}}
\abx@aux@cite{THEDESIGN}
\abx@aux@segm{0}{0}{THEDESIGN}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {2-1 }{\ignorespaces CUDA存储系统层级\relax }}{5}{table.caption.2}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {2-1 }{\ignorespaces CUDA storage system hierarchy\relax }}{5}{table.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{table-存储}{{2-1 }{5}{CUDA storage system hierarchy\relax }{table.caption.2}{}}
\newlabel{table-存储@cref}{{[table][1][]2-1 }{[1][4][]5}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2-1 }{\ignorespaces 纹理内存和其余存储系统\relax }}{5}{figure.caption.3}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2-1 }{\ignorespaces Texture memory and other memory system\relax }}{5}{figure.caption.3}}
\newlabel{Fig.TextureAndGlobal}{{2-1 }{5}{Texture memory and other memory system\relax }{figure.caption.3}{}}
\newlabel{Fig.TextureAndGlobal@cref}{{[figure][1][]2-1 }{[1][5][]5}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subparagraph}{\numberline {III}纹理内存(Texture Memory)}{5}{subparagraph.2.1.1.0.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}伏特/图灵架构新硬件}{5}{subsubsection.2.1.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subparagraph}{\numberline {I}伏特/图灵架构新硬件}{5}{subparagraph.2.1.2.0.1}}
\abx@aux@segm{0}{0}{CUTLASS}
\abx@aux@segm{0}{0}{VOLTAWHITEPAPER}
\abx@aux@cite{HMMA}
\abx@aux@segm{0}{0}{HMMA}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2-2 }{\ignorespaces 伏特架构与帕斯卡架构的流多处理器示意图\relax }}{6}{figure.caption.4}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2-2 }{\ignorespaces SM diagram of Volta and Pascal architecture\relax }}{6}{figure.caption.4}}
\newlabel{Fig.VoltaPascal}{{2-2 }{6}{SM diagram of Volta and Pascal architecture\relax }{figure.caption.4}{}}
\newlabel{Fig.VoltaPascal@cref}{{[figure][2][]2-2 }{[1][6][]6}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subparagraph}{\numberline {II}张量核心(Tensor Core)}{6}{subparagraph.2.1.2.0.2}}
\abx@aux@cite{AMPEREPOR}
\abx@aux@segm{0}{0}{AMPEREPOR}
\abx@aux@segm{0}{0}{TENSORCORE}
\abx@aux@segm{0}{0}{CUTLASS}
\abx@aux@segm{0}{0}{CUTLASS}
\abx@aux@cite{FLYNN}
\abx@aux@segm{0}{0}{FLYNN}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2-3 }{\ignorespaces 使用张量核心进行通用矩阵乘法计算的层级\cite {CUTLASS}\relax }}{7}{figure.caption.5}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2-3 }{\ignorespaces Hierarchy of GEMM using Tensor Core\relax }}{7}{figure.caption.5}}
\newlabel{Fig.Tile}{{2-3 }{7}{Hierarchy of GEMM using Tensor Core\relax }{figure.caption.5}{}}
\newlabel{Fig.Tile@cref}{{[figure][3][]2-3 }{[1][7][]7}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}线程组织形式与调度方式}{7}{subsubsection.2.1.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subparagraph}{\numberline {I}线程组织形式}{7}{subparagraph.2.1.3.0.1}}
\abx@aux@cite{BLOCKDIAG}
\abx@aux@segm{0}{0}{BLOCKDIAG}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {2-2 }{\ignorespaces 线程组织形式\relax }}{8}{table.caption.6}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {2-2 }{\ignorespaces Type of organizing threads\relax }}{8}{table.caption.6}}
\newlabel{table-粒度}{{2-2 }{8}{Type of organizing threads\relax }{table.caption.6}{}}
\newlabel{table-粒度@cref}{{[table][2][]2-2 }{[1][8][]8}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {2-3 }{\ignorespaces 可分配线程数与占用率的关系\relax }}{8}{table.caption.7}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {2-3 }{\ignorespaces Available thread number and corresponding occupancy rate\relax }}{8}{table.caption.7}}
\newlabel{table-占用率}{{2-3 }{8}{Available thread number and corresponding occupancy rate\relax }{table.caption.7}{}}
\newlabel{table-占用率@cref}{{[table][3][]2-3 }{[1][8][]8}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subparagraph}{\numberline {II}调度方式}{8}{subparagraph.2.1.3.0.2}}
\abx@aux@cite{THREADS}
\abx@aux@segm{0}{0}{THREADS}
\abx@aux@cite{DIVER}
\abx@aux@segm{0}{0}{DIVER}
\abx@aux@cite{STREAM}
\abx@aux@segm{0}{0}{STREAM}
\abx@aux@cite{PAGELOCK}
\abx@aux@segm{0}{0}{PAGELOCK}
\abx@aux@cite{TFBUILD}
\abx@aux@segm{0}{0}{TFBUILD}
\abx@aux@cite{EVENEASIER}
\abx@aux@segm{0}{0}{EVENEASIER}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}NVIDIA GPU相关软件}{9}{subsection.2.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}机器学习框架(Tensor Flow)}{9}{subsubsection.2.2.1}}
\abx@aux@cite{10.0PATCH}
\abx@aux@segm{0}{0}{10.0PATCH}
\abx@aux@cite{9.2PATCH}
\abx@aux@segm{0}{0}{9.2PATCH}
\abx@aux@cite{10.1PATCH}
\abx@aux@segm{0}{0}{10.1PATCH}
\abx@aux@cite{PTX}
\abx@aux@segm{0}{0}{PTX}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2-4 }{\ignorespaces 中间代码(PTX)格式示例\relax }}{10}{figure.caption.8}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2-4 }{\ignorespaces An example of PTX code\relax }}{10}{figure.caption.8}}
\newlabel{Fig.Inst}{{2-4 }{10}{An example of PTX code\relax }{figure.caption.8}{}}
\newlabel{Fig.Inst@cref}{{[figure][4][]2-4 }{[1][10][]10}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}CUDA}{10}{subsubsection.2.2.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}硬件代码(SASS)与中间代码(PTX)}{10}{subsubsection.2.2.3}}
\abx@aux@cite{TENSORRT}
\abx@aux@segm{0}{0}{TENSORRT}
\abx@aux@cite{TENSORRTDOC}
\abx@aux@segm{0}{0}{TENSORRTDOC}
\abx@aux@segm{0}{0}{TENSORRT}
\abx@aux@segm{0}{0}{TENSORRT}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2-5 }{\ignorespaces 一段具体的中间代码(PTX)\relax }}{11}{figure.caption.9}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2-5 }{\ignorespaces Part of actual PTX code\relax }}{11}{figure.caption.9}}
\newlabel{Fig.ActualInst}{{2-5 }{11}{Part of actual PTX code\relax }{figure.caption.9}{}}
\newlabel{Fig.ActualInst@cref}{{[figure][5][]2-5 }{[1][10][]11}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}神经网络推理工具TensorRT与相应硬件平台Jetson}{11}{subsection.2.3}}
\abx@aux@segm{0}{0}{TENSORRTDOC}
\abx@aux@segm{0}{0}{NSIGHT}
\abx@aux@cite{NVPROF}
\abx@aux@segm{0}{0}{NVPROF}
\abx@aux@segm{0}{0}{GPGPUSIM}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2-6 }{\ignorespaces TensorRT中的模块\cite {TENSORRT}\relax }}{12}{figure.caption.10}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2-6 }{\ignorespaces Modules in TensorRT\relax }}{12}{figure.caption.10}}
\newlabel{Fig.TensorRT}{{2-6 }{12}{Modules in TensorRT\relax }{figure.caption.10}{}}
\newlabel{Fig.TensorRT@cref}{{[figure][6][]2-6 }{[1][11][]12}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}性能评估(Profiling)工具}{12}{subsection.2.4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}基于GPU的机器学习应用}{13}{subsection.2.5}}
\abx@aux@segm{0}{0}{VOLTAWHITEPAPER}
\abx@aux@cite{TFCRESNET}
\abx@aux@segm{0}{0}{TFCRESNET}
\abx@aux@cite{CUDA92}
\abx@aux@segm{0}{0}{CUDA92}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {第三章}评估NVIDIA新架构GPU的机器学习应用性能}{14}{section.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}实验工具与环境}{14}{subsection.3.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}基于性能评估的Benchmark}{14}{subsection.3.2}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-1 }{\ignorespaces 实验环境\relax }}{14}{table.caption.11}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-1 }{\ignorespaces Environment\relax }}{14}{table.caption.11}}
\newlabel{table-环境}{{3-1 }{14}{Environment\relax }{table.caption.11}{}}
\newlabel{table-环境@cref}{{[table][1][]3-1 }{[1][14][]14}}
\abx@aux@segm{0}{0}{DEEPBENCH}
\abx@aux@segm{0}{0}{PTX}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-2 }{\ignorespaces 实验工具\relax }}{15}{table.caption.12}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-2 }{\ignorespaces Tools\relax }}{15}{table.caption.12}}
\newlabel{table-实验工具}{{3-2 }{15}{Tools\relax }{table.caption.12}{}}
\newlabel{table-实验工具@cref}{{[table][2][]3-2 }{[1][14][]15}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}通用矩阵乘法运算(GEMM, General Matrix Multiply)}{15}{subsubsection.3.2.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subparagraph}{\numberline {I}实验结果}{15}{subparagraph.3.2.1.0.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subparagraph}{\numberline {II}结果分析}{16}{subparagraph.3.2.1.0.2}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-1 }{\ignorespaces 半精度/单精度GEMM性能\relax }}{17}{figure.caption.13}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-1 }{\ignorespaces Performance of GEMM at Half and Single\relax }}{17}{figure.caption.13}}
\newlabel{Fig-PerfGemm}{{3-1 }{17}{Performance of GEMM at Half and Single\relax }{figure.caption.13}{}}
\newlabel{Fig-PerfGemm@cref}{{[figure][1][]3-1 }{[1][16][]17}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-2 }{\ignorespaces 输入矩阵维度与加速比的关系\relax }}{18}{figure.caption.14}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-2 }{\ignorespaces Relationship of input matrix dimension and speed-up ratio\relax }}{18}{figure.caption.14}}
\newlabel{Fig-MNKRatio}{{3-2 }{18}{Relationship of input matrix dimension and speed-up ratio\relax }{figure.caption.14}{}}
\newlabel{Fig-MNKRatio@cref}{{[figure][2][]3-2 }{[1][16][]18}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-3 }{\ignorespaces 使用模板库测得的GEMM性能\relax }}{19}{figure.caption.15}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-3 }{\ignorespaces GEMM Performance with CUTLASS\relax }}{19}{figure.caption.15}}
\newlabel{Fig-GEMM-CUTLASS}{{3-3 }{19}{GEMM Performance with CUTLASS\relax }{figure.caption.15}{}}
\newlabel{Fig-GEMM-CUTLASS@cref}{{[figure][3][]3-3 }{[1][16][]19}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-4 }{\ignorespaces 开启张量核心下矩阵乘加运算的性能分析(API Calls)\relax }}{19}{figure.caption.16}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-4 }{\ignorespaces Performance analysis of GEMM with Tensor Core On (API Calls)\relax }}{19}{figure.caption.16}}
\newlabel{Fig.GEMMPROFTF}{{3-4 }{19}{Performance analysis of GEMM with Tensor Core On (API Calls)\relax }{figure.caption.16}{}}
\newlabel{Fig.GEMMPROFTF@cref}{{[figure][4][]3-4 }{[1][16][]19}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-5 }{\ignorespaces 关闭张量核心下矩阵乘加运算的性能分析(API Calls)\relax }}{20}{figure.caption.17}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-5 }{\ignorespaces Performance analysis of GEMM with Tensor Core Off (API Calls)\relax }}{20}{figure.caption.17}}
\newlabel{Fig.GEMMPROFNOTF}{{3-5 }{20}{Performance analysis of GEMM with Tensor Core Off (API Calls)\relax }{figure.caption.17}{}}
\newlabel{Fig.GEMMPROFNOTF@cref}{{[figure][5][]3-5 }{[1][16][]20}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-3 }{\ignorespaces GPGPU-SIM测得的各指令运行所需时钟周期(图灵架构)\relax }}{20}{table.caption.18}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-3 }{\ignorespaces Clock cycle the instructions will cost based on GPGPU-SIM(Turing Arch)\relax }}{20}{table.caption.18}}
\newlabel{table-时钟周期}{{3-3 }{20}{Clock cycle the instructions will cost based on GPGPU-SIM(Turing Arch)\relax }{table.caption.18}{}}
\newlabel{table-时钟周期@cref}{{[table][3][]3-3 }{[1][16][]20}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-6 }{\ignorespaces 一段由wmma指令编译出的机器指令\relax }}{20}{figure.caption.19}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-6 }{\ignorespaces Part of SASS code complied from PTX code: wmma\relax }}{20}{figure.caption.19}}
\newlabel{Fig.HMMASASS}{{3-6 }{20}{Part of SASS code complied from PTX code: wmma\relax }{figure.caption.19}{}}
\newlabel{Fig.HMMASASS@cref}{{[figure][6][]3-6 }{[1][16][]20}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-7 }{\ignorespaces 开启张量核心下矩阵乘加运算的性能分析(上下文切换)\relax }}{21}{figure.caption.20}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-7 }{\ignorespaces Performance analysis of GEMM with Tensor Core On (Context Switch)\relax }}{21}{figure.caption.20}}
\newlabel{Fig.GEMMSIGHTTF}{{3-7 }{21}{Performance analysis of GEMM with Tensor Core On (Context Switch)\relax }{figure.caption.20}{}}
\newlabel{Fig.GEMMSIGHTTF@cref}{{[figure][7][]3-7 }{[1][16][]21}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-8 }{\ignorespaces 关闭张量核心下矩阵乘加运算的性能分析(上下文切换)\relax }}{21}{figure.caption.21}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-8 }{\ignorespaces Performance analysis of GEMM with Tensor Core Off (Context Switch)\relax }}{21}{figure.caption.21}}
\newlabel{Fig.GEMMSIGHTNOTF}{{3-8 }{21}{Performance analysis of GEMM with Tensor Core Off (Context Switch)\relax }{figure.caption.21}{}}
\newlabel{Fig.GEMMSIGHTNOTF@cref}{{[figure][8][]3-8 }{[1][16][]21}}
\abx@aux@segm{0}{0}{PTX}
\abx@aux@segm{0}{0}{PTX}
\abx@aux@cite{2080TI}
\abx@aux@segm{0}{0}{2080TI}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-9 }{\ignorespaces 半精度/单精度GEMM性能(按加速比排序)\relax }}{23}{figure.caption.22}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-9 }{\ignorespaces Performance of GEMM at Half and Single (Sorted by speed-up ratio)\relax }}{23}{figure.caption.22}}
\newlabel{Fig-PerfGemmByratio}{{3-9 }{23}{Performance of GEMM at Half and Single (Sorted by speed-up ratio)\relax }{figure.caption.22}{}}
\newlabel{Fig-PerfGemmByratio@cref}{{[figure][9][]3-9 }{[1][22][]23}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-10 }{\ignorespaces 半精度/单精度GEMM性能(按加速比排序，根据维度K特征着色)\relax }}{24}{figure.caption.23}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-10 }{\ignorespaces Performance of GEMM at Half and Single (Sorted by speed-up ratio, colored with feature of K)\relax }}{24}{figure.caption.23}}
\newlabel{Fig-PerfGemmByratioTri}{{3-10 }{24}{Performance of GEMM at Half and Single (Sorted by speed-up ratio, colored with feature of K)\relax }{figure.caption.23}{}}
\newlabel{Fig-PerfGemmByratioTri@cref}{{[figure][10][]3-10 }{[1][22][]24}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-11 }{\ignorespaces 官方文档给出的wmma指令支持的分割尺寸\cite {PTX}\relax }}{25}{figure.caption.24}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-11 }{\ignorespaces Matrix size supported in wmma instruction based on official documentation\relax }}{25}{figure.caption.24}}
\newlabel{Fig.WMMADOC}{{3-11 }{25}{Matrix size supported in wmma instruction based on official documentation\relax }{figure.caption.24}{}}
\newlabel{Fig.WMMADOC@cref}{{[figure][11][]3-11 }{[1][22][]25}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}矩阵乘法运算}{25}{subsubsection.3.2.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subparagraph}{\numberline {I}实验结果}{25}{subparagraph.3.2.2.0.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subparagraph}{\numberline {II}结果分析}{25}{subparagraph.3.2.2.0.2}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-12 }{\ignorespaces 使用和不使用cuBLAS库时的矩阵乘法运算性能\relax }}{26}{figure.caption.25}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-12 }{\ignorespaces Performance of Matrix Multiply with and without cuBLAS library\relax }}{26}{figure.caption.25}}
\newlabel{Fig.CUBLASPerf}{{3-12 }{26}{Performance of Matrix Multiply with and without cuBLAS library\relax }{figure.caption.25}{}}
\newlabel{Fig.CUBLASPerf@cref}{{[figure][12][]3-12 }{[1][25][]26}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-4 }{\ignorespaces 实验中的几种卷积计算方式\relax }}{26}{table.caption.26}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-4 }{\ignorespaces Methods to calculate convolution\relax }}{26}{table.caption.26}}
\newlabel{table-CONV}{{3-4 }{26}{Methods to calculate convolution\relax }{table.caption.26}{}}
\newlabel{table-CONV@cref}{{[table][4][]3-4 }{[1][26][]26}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}卷积运算}{26}{subsubsection.3.2.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subparagraph}{\numberline {I}实验结果}{26}{subparagraph.3.2.3.0.1}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-13 }{\ignorespaces 使用不同计算方法的卷积计算速度\relax }}{27}{figure.caption.27}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-13 }{\ignorespaces Performance in speed of convolution based on different algorithm\relax }}{27}{figure.caption.27}}
\newlabel{Fig.CONVPerf}{{3-13 }{27}{Performance in speed of convolution based on different algorithm\relax }{figure.caption.27}{}}
\newlabel{Fig.CONVPerf@cref}{{[figure][13][]3-13 }{[1][26][]27}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subparagraph}{\numberline {II}结果分析}{27}{subparagraph.3.2.3.0.2}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-14 }{\ignorespaces 使用不同计算方法的卷积计算速度(小图像)\relax }}{28}{figure.caption.28}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-14 }{\ignorespaces Performance in speed of convolution based on different algorithm(Small images)\relax }}{28}{figure.caption.28}}
\newlabel{Fig.CONVSubPerf}{{3-14 }{28}{Performance in speed of convolution based on different algorithm(Small images)\relax }{figure.caption.28}{}}
\newlabel{Fig.CONVSubPerf@cref}{{[figure][14][]3-14 }{[1][26][]28}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-15 }{\ignorespaces 使用不同计算方法的卷积计算精度\relax }}{28}{figure.caption.29}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-15 }{\ignorespaces Performance in accuracy of convolution based on different algorithm\relax }}{28}{figure.caption.29}}
\newlabel{Fig.CONVPr}{{3-15 }{28}{Performance in accuracy of convolution based on different algorithm\relax }{figure.caption.29}{}}
\newlabel{Fig.CONVPr@cref}{{[figure][15][]3-15 }{[1][27][]28}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-5 }{\ignorespaces 网络推理实验中使用的网络及特点\relax }}{29}{table.caption.30}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-5 }{\ignorespaces Networks and their features used in inferencing\relax }}{29}{table.caption.30}}
\newlabel{table-NETWORKS}{{3-5 }{29}{Networks and their features used in inferencing\relax }{table.caption.30}{}}
\newlabel{table-NETWORKS@cref}{{[table][5][]3-5 }{[1][29][]29}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.4}基于TensorRT的神经网络推理}{29}{subsubsection.3.2.4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subparagraph}{\numberline {I}实验结果}{29}{subparagraph.3.2.4.0.1}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-16 }{\ignorespaces 不同网络推理性能提升幅度\relax }}{30}{figure.caption.31}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-16 }{\ignorespaces Increasing in inferencing of networks with different structure\relax }}{30}{figure.caption.31}}
\newlabel{Fig.INFER}{{3-16 }{30}{Increasing in inferencing of networks with different structure\relax }{figure.caption.31}{}}
\newlabel{Fig.INFER@cref}{{[figure][16][]3-16 }{[1][29][]30}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-17 }{\ignorespaces 不同网络推理加速比\relax }}{30}{figure.caption.32}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-17 }{\ignorespaces Speedup ratio in inferencing of networks with different structure\relax }}{30}{figure.caption.32}}
\newlabel{Fig.INFERSPEEDUP}{{3-17 }{30}{Speedup ratio in inferencing of networks with different structure\relax }{figure.caption.32}{}}
\newlabel{Fig.INFERSPEEDUP@cref}{{[figure][17][]3-17 }{[1][29][]30}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subparagraph}{\numberline {II}结果分析}{31}{subparagraph.3.2.4.0.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}基于CUDA源码的应用}{31}{subsection.3.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}基于cuDNN的卷积神经网络(CNN)}{31}{subsubsection.3.3.1}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-6 }{\ignorespaces 实验中图像、卷积核参数\relax }}{32}{table.caption.33}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-6 }{\ignorespaces Parameter of image, convolution kernel\relax }}{32}{table.caption.33}}
\newlabel{table-CNNMETA}{{3-6 }{32}{Parameter of image, convolution kernel\relax }{table.caption.33}{}}
\newlabel{table-CNNMETA@cref}{{[table][6][]3-6 }{[1][31][]32}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-7 }{\ignorespaces 实验中网络超参数(通道、批大小、卷积核个数)\relax }}{33}{table.caption.34}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-7 }{\ignorespaces Meta parameter (including channel, batch size and kernel amount)\relax }}{33}{table.caption.34}}
\newlabel{table-CNNMETA1}{{3-7 }{33}{Meta parameter (including channel, batch size and kernel amount)\relax }{table.caption.34}{}}
\newlabel{table-CNNMETA1@cref}{{[table][7][]3-7 }{[1][31][]33}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-8 }{\ignorespaces 卷积神经网络中的3个计算部分\relax }}{33}{table.caption.35}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-8 }{\ignorespaces 3 parts in Convulutional Neural Network\relax }}{33}{table.caption.35}}
\newlabel{table-CONVSTEP}{{3-8 }{33}{3 parts in Convulutional Neural Network\relax }{table.caption.35}{}}
\newlabel{table-CONVSTEP@cref}{{[table][8][]3-8 }{[1][31][]33}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-9 }{\ignorespaces cuDNNConvolution中前向传播算法\relax }}{33}{table.caption.36}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-9 }{\ignorespaces Forward algorithm in cuDNN\relax }}{33}{table.caption.36}}
\newlabel{table-FWDALGO}{{3-9 }{33}{Forward algorithm in cuDNN\relax }{table.caption.36}{}}
\newlabel{table-FWDALGO@cref}{{[table][9][]3-9 }{[1][31][]33}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-10 }{\ignorespaces cudnnConvolution中反向传播算法\relax }}{33}{table.caption.37}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-10 }{\ignorespaces Backward algorithm in cudnn\relax }}{33}{table.caption.37}}
\newlabel{table-BWDALGO}{{3-10 }{33}{Backward algorithm in cudnn\relax }{table.caption.37}{}}
\newlabel{table-BWDALGO@cref}{{[table][10][]3-10 }{[1][31][]33}}
\abx@aux@cite{ERICYUAN}
\abx@aux@segm{0}{0}{ERICYUAN}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subparagraph}{\numberline {I}实验结果}{34}{subparagraph.3.3.1.0.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subparagraph}{\numberline {II}结果分析}{34}{subparagraph.3.3.1.0.2}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-18 }{\ignorespaces 实验中卷积神经网络不同过程性能(第一部分)\relax }}{35}{figure.caption.38}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-18 }{\ignorespaces Performance of different process in CNN in experiment(Part 1)\relax }}{35}{figure.caption.38}}
\newlabel{Fig.CNNPerf-1}{{3-18 }{35}{Performance of different process in CNN in experiment(Part 1)\relax }{figure.caption.38}{}}
\newlabel{Fig.CNNPerf-1@cref}{{[figure][18][]3-18 }{[1][31][]35}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-19 }{\ignorespaces 实验中卷积神经网络不同过程性能(第二部分)\relax }}{36}{figure.caption.39}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-19 }{\ignorespaces Performance of different process in CNN in experiment(Part 2)\relax }}{36}{figure.caption.39}}
\newlabel{Fig.CNNPerf-2}{{3-19 }{36}{Performance of different process in CNN in experiment(Part 2)\relax }{figure.caption.39}{}}
\newlabel{Fig.CNNPerf-2@cref}{{[figure][19][]3-19 }{[1][31][]36}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-20 }{\ignorespaces 实验中卷积神经网络不同过程性能整合\relax }}{37}{figure.caption.40}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-20 }{\ignorespaces Collection of performance of different process in CNN in experiment\relax }}{37}{figure.caption.40}}
\newlabel{Fig.CNNPerf3Part}{{3-20 }{37}{Collection of performance of different process in CNN in experiment\relax }{figure.caption.40}{}}
\newlabel{Fig.CNNPerf3Part@cref}{{[figure][20][]3-20 }{[1][34][]37}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-11 }{\ignorespaces ReLU相关运算API及耗时\relax }}{38}{table.caption.41}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-11 }{\ignorespaces APIs and time spent on ReLU related calculation\relax }}{38}{table.caption.41}}
\newlabel{table-RELU}{{3-11 }{38}{APIs and time spent on ReLU related calculation\relax }{table.caption.41}{}}
\newlabel{table-RELU@cref}{{[table][11][]3-11 }{[1][34][]38}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-21 }{\ignorespaces 使用cuDNN中直接计算方法的性能对比\relax }}{39}{figure.caption.42}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-21 }{\ignorespaces Performance of DIRECT algorithm in cuDNN\relax }}{39}{figure.caption.42}}
\newlabel{Fig.CNNDIRECT}{{3-21 }{39}{Performance of DIRECT algorithm in cuDNN\relax }{figure.caption.42}{}}
\newlabel{Fig.CNNDIRECT@cref}{{[figure][21][]3-21 }{[1][34][]39}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-22 }{\ignorespaces 使用纹理内存优化的小尺寸图象前向传播性能\relax }}{39}{figure.caption.43}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-22 }{\ignorespaces Performance of forward on small image optimized by texture memory\relax }}{39}{figure.caption.43}}
\newlabel{Fig.TEXVSSHARED}{{3-22 }{39}{Performance of forward on small image optimized by texture memory\relax }{figure.caption.43}{}}
\newlabel{Fig.TEXVSSHARED@cref}{{[figure][22][]3-22 }{[1][38][]39}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-23 }{\ignorespaces 使用纹理内存计算卷积的代码段\relax }}{40}{figure.caption.44}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-23 }{\ignorespaces Part of the code of calculating convolution by texture memory\relax }}{40}{figure.caption.44}}
\newlabel{Fig.TexCode}{{3-23 }{40}{Part of the code of calculating convolution by texture memory\relax }{figure.caption.44}{}}
\newlabel{Fig.TexCode@cref}{{[figure][23][]3-23 }{[1][38][]40}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-24 }{\ignorespaces 卷积神经网络中图像通道、卷积核个数、输入批大小的影响\relax }}{41}{figure.caption.45}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-24 }{\ignorespaces Performance and Channel, amount of Conv kernel, batch size of CNN\relax }}{41}{figure.caption.45}}
\newlabel{Fig-CNNMNK}{{3-24 }{41}{Performance and Channel, amount of Conv kernel, batch size of CNN\relax }{figure.caption.45}{}}
\newlabel{Fig-CNNMNK@cref}{{[figure][24][]3-24 }{[1][38][]41}}
\abx@aux@cite{SMO}
\abx@aux@segm{0}{0}{SMO}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-12 }{\ignorespaces SMO-SVM中使用的矩阵计算方法\relax }}{42}{table.caption.46}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-12 }{\ignorespaces Matrix calculation algorithm in SMO-SVM\relax }}{42}{table.caption.46}}
\newlabel{table-SMOSVM}{{3-12 }{42}{Matrix calculation algorithm in SMO-SVM\relax }{table.caption.46}{}}
\newlabel{table-SMOSVM@cref}{{[table][12][]3-12 }{[1][42][]42}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}并行最小序列优化支持向量机(SMO-SVM)}{42}{subsubsection.3.3.2}}
\newlabel{eqn.SVMRAW}{{1}{42}{并行最小序列优化支持向量机(SMO-SVM)}{equation.3.1}{}}
\newlabel{eqn.SVMRAW@cref}{{[equation][1][]1}{[1][42][]42}}
\newlabel{eqn.SVMDUAL}{{2}{42}{并行最小序列优化支持向量机(SMO-SVM)}{equation.3.2}{}}
\newlabel{eqn.SVMDUAL@cref}{{[equation][2][]2}{[1][42][]42}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subparagraph}{\numberline {I}实验结果}{42}{subparagraph.3.3.2.0.1}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-25 }{\ignorespaces SMO-SVM训练时间\relax }}{43}{figure.caption.47}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3-25 }{\ignorespaces Training time of SMO-SVM\relax }}{43}{figure.caption.47}}
\newlabel{Fig-SMOSVMRES}{{3-25 }{43}{Training time of SMO-SVM\relax }{figure.caption.47}{}}
\newlabel{Fig-SMOSVMRES@cref}{{[figure][25][]3-25 }{[1][42][]43}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subparagraph}{\numberline {II}结果分析}{43}{subparagraph.3.3.2.0.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}基于Tensor Flow框架的应用}{43}{subsection.3.4}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-13 }{\ignorespaces 基于Tensor Flow框架的CNN的改进\relax }}{44}{table.caption.48}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-13 }{\ignorespaces Improvment in CNN based on Tensor Flow\relax }}{44}{table.caption.48}}
\newlabel{table-TFList}{{3-13 }{44}{Improvment in CNN based on Tensor Flow\relax }{table.caption.48}{}}
\newlabel{table-TFList@cref}{{[table][13][]3-13 }{[1][44][]44}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subparagraph}{\numberline {I}实验结果}{44}{subparagraph.3.4.0.0.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subparagraph}{\numberline {II}结果分析}{44}{subparagraph.3.4.0.0.2}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-14 }{\ignorespaces 基于Tensor Flow框架的CNN的优化结果\relax }}{45}{table.caption.49}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3-14 }{\ignorespaces Optimization result in CNN based on Tensor Flow\relax }}{45}{table.caption.49}}
\newlabel{table-TFRES}{{3-14 }{45}{Optimization result in CNN based on Tensor Flow\relax }{table.caption.49}{}}
\newlabel{table-TFRES@cref}{{[table][14][]3-14 }{[1][44][]45}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {第四章}总结与展望}{46}{section.4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}总结}{46}{subsection.4.1}}
\abx@aux@cite{SCALABLITY}
\abx@aux@segm{0}{0}{SCALABLITY}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}展望}{47}{subsection.4.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subparagraph}{\numberline {I}更细粒度的同步机制}{47}{subparagraph.4.2.0.0.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subparagraph}{\numberline {II}规模更大的矩阵乘加指令}{47}{subparagraph.4.2.0.0.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subparagraph}{\numberline {III}针对稀疏矩阵优化的矩阵乘加指令}{47}{subparagraph.4.2.0.0.3}}
\FN@pp@footnotehinttrue 
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{参考文献}{48}{section*.50}}
\FN@pp@footnotehinttrue 
\abx@aux@refcontextdefaultsdone
\abx@aux@defaultrefcontext{0}{TESLAV100}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{TENSORCORE}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{NVLINK2}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{CUTLASS}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{VOLTAWHITEPAPER}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{EXASCLEDL}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{MODELING}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{JETSONNANO}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{CUDAX}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{GPUFORML}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{KNNG}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{SMOSVM}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{BAYESINF}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{JAPANESSAY}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{LENET}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{NNML}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{GPGPUSIM}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{GPGPUSIM2}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{NSIGHT}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{DEEPBENCH}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{RESNET}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{MOBILE}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{EXPLORING}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{HIER}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{CUDAPROG}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{THEDESIGN}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{HMMA}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{AMPEREPOR}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{FLYNN}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{BLOCKDIAG}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{THREADS}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{DIVER}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{STREAM}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{PAGELOCK}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{TFBUILD}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{EVENEASIER}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{10.0PATCH}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{9.2PATCH}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{10.1PATCH}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{PTX}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{TENSORRT}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{TENSORRTDOC}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{NVPROF}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{TFCRESNET}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{CUDA92}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{2080TI}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{ERICYUAN}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{SMO}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{SCALABLITY}{none/global//global/global}
\FN@pp@footnotehinttrue 
\FN@pp@footnotehinttrue 
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{致谢}{51}{section*.52}}
