\clearpage                                          %       


\setcounter{page}{1} 
\pagenumbering{Roman}% Roman page numbers                             %
\input{paper_info.tex}                          %
\renewcommand\abstractname{\bfseries \heiti \zihao{3}摘\hspace{1cm}要}  %
\addcontentsline{toc}{section}{摘要}
\begin{abstract}\zihao{5}\songti                    %
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\vspace{3em}
	\par 本文主要针对NVIDIA新架构的GPU(图灵架构)为机器学习应用带来的性能提升进行研究，由于目前实际使用中的应用很难达到NVIDIA官方宣传的性能提升幅度，故本文将从应用类型、代码结构结合硬件、指令特征对这一现象进行研究，并提出相应的建议。
	\par 本文采用自底向上结构，使用定量方法，通过不同世代的硬件与SDK进行横向比较，以及同一世代硬件与SDK和不同类型应用进行纵向比较研究新架构硬件的特点，而硬件中的张量核心是本文的重点研究对象。
	\par 首先，实验从底层的基于性能评估的Benchmark出发，考察了矩阵乘加、矩阵乘法、卷积运算的性能，并从指令、硬件机制等方面进行了分析，作为基准。在这基础上，借助基于CUDA C++源码的卷积神经网络与最小序列优化支持向量机，考察了若干模块整合后应用的总体性能，从调用、运行情况对结果进行分析，并从稀疏矩阵、纹理内存等方面尝试优化。最后，结合既得的实验结论，对基于Tensor Flow-GPU框架的简单卷积神经网络进行评估，并在框架的底层源码层面从卷积方式、纹理内存、超参数、数据精度等方面进行优化。除神经网络的训练外，实验还对推理过程进行评估，并使用TensorRT以及对应的硬件Jetson进行加速。
	\par 文章的最后，根据实验结果对指令集、同步机制的下一步发展做出了合理的展望。
	\newline
	\newline
	{\bfseries \sffamily\zihao{5} 关键词：} \zihao{5}{\rmfamily \KeywordsCHS}
\end{abstract}                                                    %
%通常你不需要修改这部分内容
\clearpage                         
\renewcommand\abstractname{\bfseries \zihao{3}Abstract}  
\addcontentsline{toc}{section}{Abstract}                 %
\begin{abstract}\zihao{5}                                         %
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\vspace{3em}
	\par This paper is focusing on the performance improvement in Machine Learning application brought by NVIDIA's new architecture GPU (Volta and Turing Architecture). Since currently the Machine Learning application used in practice can hardly get as much improvement as mentioned in NVIDIA's official White Paper, so, this paper will research this condition through the type of applications, the structure of the code combined with features of hardware and instructions, thus give corresponding recommendations.
	\par This paper mainly uses quantitative methods based on the structure from bottom to the top, by doing both horizontal comparation with hardware and SDK of different generations and vertical comparation with different types of applications running on the same generation of hardware and SDK, the feature of new hardware can be revealed. In the new hardware, Tensor Core will be the key research subject.
	\par First, the experiment start with Benchmark oriented to performance evaluation, the performance of GEMM, matrix multiply and convolution are investigated and analyzed in instructions, hardware functionality, etc. With the result of Benchmark, the experiment use CNN and SMO-SVM based on CUDA C++ to investigate the performance of several modules integrating to a whole application, analyze them from function call, context switch, etc. and try to  optimize the applications using sparse matrix, texture memory, etc. At the end of the experiment, combining the results of Benchmark and CUDA C++, a simple CNN based on Tensor Flow-GPU is investigated and optimized in Texture memory, methods to calculate convolution, meta-parameter, precision, etc. In addition to training stage of neural network, inference stage is also investigated and optimized with TensorRT and corresponding hardware Jetson. 
	\par Finally, several reasonable assumptions and imaginations about next generation hardware are made based on the result in the experiment.
	\newline
	\newline
	{\bfseries \zihao{5} Keywords：} {\zihao{5} \KeywordsENG}        %   
\end{abstract}                                                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%